import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.json.*;
import java.io.IOException;




public class WordCountMapper extends Mapper<LongWritable,Text,Text,IntWritable> {
@Override

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException{


	String id;
	String quantity;
    String line = value.toString();
    String[] tuple = line.split("\\n");
 
    for(int i=0; i < tuple.length;i++){
    	JSONObject json = new JSONObject(tuple[i]);
    }
    
//    for (String word : line.split(" ")){
//        if(word.length()>0){
//            context.write(new Text(word),new IntWritable(1));
//        }
//    }
}

}